apply plugin: 'java'
apply plugin: 'maven'
apply plugin: 'signing'
apply plugin: 'jacoco'
apply plugin: 'org.junit.platform.gradle.plugin'

sourceCompatibility = 1.8
compileJava.options.encoding = 'UTF-8'


group = "com.github.zuinnote"
archivesBaseName = "hadoopcryptoledger-hiveudf"
version = "1.2.0"





jacocoTestReport {
    reports {
        xml.enabled true
        csv.enabled true
    }
}



// Integrate JaCoCo for jUnit5
project.afterEvaluate {
    def junitPlatformTestTask = project.tasks.getByName('junitPlatformTest')

    // configure jacoco to analyze the junitPlatformTest task
    jacoco {
        applyTo junitPlatformTestTask
    }

    // create junit platform jacoco task
    project.task(type: JacocoReport, "junitPlatformJacocoReport",
            {
                sourceDirectories = files("./src/main")
                classDirectories = files("$buildDir/classes/main")
                executionData junitPlatformTestTask
            })
}

repositories {
    mavenCentral()
     mavenLocal()
    // workaround for certain dependencies of hive-exec
    maven {
    	url "http://conjars.org/repo"
    }



}

test {
    testLogging.showStandardStreams = true
}

configurations {
	provided
	integrationTestCompile.extendsFrom testCompile
    	integrationTestRuntime.extendsFrom testRuntime
    	extraJar
}

eclipse {

  classpath {
    plusConfigurations += [ configurations.provided ]
  }
}

sourceSets {
    main.compileClasspath += configurations.provided
    test.compileClasspath += configurations.provided
    test.runtimeClasspath += configurations.provided
    integrationTest {
        java {
            compileClasspath += main.output + test.output + configurations.provided
            runtimeClasspath += main.output + test.output + configurations.provided
            srcDir file('src/integration-test/java')
        }
        resources.srcDir file('src/integration-test/resources')
    }
}

dependencies {
   // hadoop lib for driver
     provided("org.apache.hadoop:hadoop-client:2.7.0")
       // hadoop crypto ledger library
   compile("com.github.zuinnote:hadoopcryptoledger-fileformat:1.2.0")
   compile("com.github.zuinnote:hadoopcryptoledger-hiveserde:1.2.0")
   // we need to mandatory add the BC library
     provided("org.bouncycastle:bcprov-ext-jdk15on:1.58")
    // hive serde API
   provided("org.apache.hive:hive-serde:1.2.0")
   provided("org.apache.hive:hive-exec:1.2.0")
   // log4j2
   provided("org.apache.logging.log4j:log4j-api:2.9.1")
   // test
    testCompile group: 'org.junit.jupiter', name: 'junit-jupiter-api', version: '5.0.3'
	testRuntime group: 'org.junit.jupiter', name: 'junit-jupiter-engine', version: '5.0.3'
}

jar {
    manifest {
        attributes 'Implementation-Title': 'ZuInnoTe - Hadoop CryptoLedger Analytics Library - Hive UDF', 'Implementation-Version': version,
        'Class-Path': configurations.runtime.files.collect {"$it.name"}.join(' ')
    }

    baseName = 'hadoopcryptoledger-hiveudf'
 
   // note this builds one fat jar and it is not recommended for production use - just for illustration purpose
      from (configurations.compile.collect { entry -> zipTree(entry) }) {
        exclude 'META-INF/*.SF'
        exclude 'META-INF/*.DSA'
        exclude 'META-INF/*.RSA'
    }
    
}

javadoc.classpath += configurations.provided
task hadoopCryptoLedgerJavaDocs(type: Jar) {
  classifier = 'javadoc'
  from javadoc
}

task sourcesJar(type: Jar) {
    classifier = 'sources'
    from sourceSets.main.allSource
}

artifacts {
    archives hadoopCryptoLedgerJavaDocs, sourcesJar
}
